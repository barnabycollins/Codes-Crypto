% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[11pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage[a4paper,left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
%\usepackage{geometry} % to change the page dimensions
% \geometry{a4paper} % or letterpaper (US) or a5paper or....
% \geometry{margin=0in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options

\usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{logicproof}
\usepackage{tikz}
\usetikzlibrary{arrows,petri,topaths}
\usepackage{float}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{textcomp}
\usepackage[T1]{fontenc}
% These packages are all incorporated in the memoir class to one degree or another...

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\sffamily\thepage\normalfont}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!
\newcommand{\qedsymbol}{\rightline{$\blacksquare$}}
\newcommand{\textapprox}{\raisebox{0.5ex}{\texttildelow}}
\renewcommand{\familydefault}{\sfdefault}
%\renewcommand{\thesection}{Idea \arabic{section}:}

\usepackage[style=numeric-comp]{biblatex}

%%% END Article customizations

%%% The "real" document content comes below...

\title{\vspace{-1.6cm}Attacking DES on a what3words address}
%\author{}
\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 

\begin{document}
\maketitle

\vspace{-1.5cm}

\section{Initial Thoughts \& Information}

As soon as I saw that ECB mode had been used, my first thought was of the fact that each 64-bit block is encrypted totally independently - that is, every 64 bits (or 8 characters) can be analysed completely separately. For a brute-force attack, this means that an attacker only needs to find the right 8-character plaintext for each consecutive ciphertext block and concatenate them, rather than guess the whole input in one go.

The provision of an exe file containing the encryption key did provide the opportunity to decompile that file, but I thought that would compromise the spirit of the coursework so decided to focus on other options first.

\subsection{My Computer}

The computer being used for this coursework was my desktop, which has an 8-core / 16-thread AMD Ryzen 7 1700 (overclocked to 3.7GHz), 16GB of RAM and plenty of free storage space. The single-core performance of the 1700 is very good, but its real strength is its multicore throughput, so I planned to leverage this.

\section{Initial attempts}

My first idea was to simply bruteforce every possible 64-bit string to see how long it would take: after a bit of experimentation I found that it would take time on the order of 34 years. Since this would mean submitting the coursework quite late, I decided that idea might be a bit impractical. I also briefly researched more intelligent methods like differential cryptanalysis, but found that even with chosen plaintexts there would not be any particular performance improvement when compared with the advantage I had as a result of knowing the structure of the input.

\section{Dictionary attack}

\subsection{Initial attack}

The clear next step was to try a dictionary attack, generating possible what3words addresses from a \href{https://github.com/dwyl/english-words/blob/master/words_dictionary.json}{dictionary of \textapprox{}370,000 English words}. I initially started generating every possible what3words address before realising that this was a bit of a Bad Idea™ and would take an unreasonable quantity of time. I then had the realisation that I could limit the generated addresses to be exactly 16 characters long, since this was the length of the cipher text and no mention of padding had been made in the coursework brief. I also found anecdotally that what3words seemed to only use words comprising 4 or more characters and was therefore able to restrict the words to only those which were 4, 5 or 6 characters long. All of these adjustments did improve things, but they were still taking an unreasonable quantity of time to generate. The memory usage also was quite excessive throughout this stage, thanks to the large sets of potential addresses.

I then had the idea of generating first and second halves separately - this would remove a lot of redundancy because, for example, four different 16-character addresses could be summarised by five 8-character ones:

\vspace{-0.3cm}

$$
\begin{matrix}
\verb|drops.rings.land| & \verb|drops.rinks.tall| & \verb|drops.ribs.desks| & \verb|drops.river.also|
\end{matrix}
$$
$$
\begin{matrix}
\verb|drops.ri| & \verb|ngs.land| & \verb|nks.tall| & \verb|bs.desks| & \verb|ver.also|
\end{matrix}
$$

saving 24 characters in this very small example. This meant that the set of items to check would be significantly smaller, especially at large scale, where thousands of full addresses would match to a single half. With this efficiency improvement in place it only took a couple of minutes to generate every possible half of a 16-character what3words address.

In this way I generated 36,098,043 first halves and 38,196,414 second halves. I then wrote code to use \verb|encrypt.exe| to try all first halves, and found that it would run in a timeframe that wasn't totally unreasonable, so used the Python \verb|multiprocessing| module to parallelise it on all 16 threads. Following a series of runs of 50,000 first-halves I found that with this method I was able to test one half-address roughly every 0.027 seconds on average, putting me at roughly 550 hours (or around two weeks) to try every single possibility. Clearly this was not ideal, but I ran batches on the first half for a day or so, storing a list of \textapprox{}1.8m checked first halves to disk, until I had a new idea:

\subsection{Using a smaller dictionary}

I noticed that the large dictionary contained an overwhelming number of obscure words like 'hokes' and 'reina', and did a small amount of research to see if there were any smaller word lists that contained every 'commonly-used' (ie, not obscure) word. I couldn't find any, but I did find a \href{https://github.com/first20hours/google-10000-english/blob/master/google-10000-english-no-swears.txt}{list of the most frequent 10,000 English words} based on a dataset from Google. I used this to generate a set of more likely what3words address halves.

Running this gave me only 1,826,012 first halves and 1,695,629 second halves. Trying every first half after subtracting those that had already been tested took roughly 10 hours in total, and eventually yielded the first half!

$$
\verb|tile.bil|
$$

I then adjusted the code to generate a list of second halves with the second word filtered to only include those that began with \verb|bil|. This gave me 4225 possible second halves, which were exhausted in 90 seconds with the answer:

$$
\verb|ls.print|
$$

\section{Result}

In summary, I found the following address:

$$
\verb|tile.bills.print|
$$

which I found to point to an unassuming car park in Philadelphia, USA. I must admit, this was initially a little underwhelming because I'd been expecting it to point to the top-secret location of a French nuclear bunker or a landmark or something. However, searching for the landscaping business at that location led me to stories I had seen before about Donald Trump's ill-fated mid-election press conference where Four Seasons Total Landscaping had been booked instead of Four Seasons Hotel. Touché!

\section{Reflections}

Alternative options that I had considered include using the \href{https://developer.what3words.com/tutorial/python}{what3words AutoSuggest API}. I also noticed from profiling that encrypt.exe wasn't making great use of my CPU, and seemed to include a lot of overheads with each run, stopping it from performing the actual DES computations very efficiently. Since completing, I realised that I could have 'batched' several concatenated plaintexts into this file at once, rather than testing one at a time, to reduce the impacts of these overheads. This strategy would probably have allowed me to complete each step several times more quickly, so if attempting again I would apply it.


\end{document}
